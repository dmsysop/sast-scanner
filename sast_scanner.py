import os
import sys
import json
import atexit
import hashlib
import subprocess
from pathlib import Path
from pymongo import MongoClient
from dotenv import load_dotenv

load_dotenv()

destination = sys.argv[1]

if len(sys.argv) < 2:
    print("âŒ Erro: Caminho do projeto nÃ£o informado.")
    sys.exit(1)

SCAN_DIR = f"/app/{destination}"

# Definir configuraÃ§Ãµes do MongoDB
MONGO_URI = os.getenv("MONGO_URI")
MONGO_DB_NAME = os.getenv("MONGO_DB_NAME", "sast_cache")
MONGO_COLLECTION = os.getenv("MONGO_COLLECTION", "cache")

# Inicializar variÃ¡veis
client = None
db = None
cache_collection = None

IGNORED_DIRS = {"node_modules", "venv", "__pycache__", "vendor"}

if MONGO_URI:
    try:
        client = MongoClient(MONGO_URI, serverSelectionTimeoutMS=5000)
        db = client.get_database(MONGO_DB_NAME)
        
        # Criar o nome da coleÃ§Ã£o com base no destino
        collection_name = f"{destination}_{MONGO_COLLECTION}"
        
        # Verificar o comprimento do nome da coleÃ§Ã£o e garantir que nÃ£o ultrapasse 255 caracteres
        if len(collection_name) > 255:
            raise ValueError(f"Nome da coleÃ§Ã£o `{collection_name}` excede o limite de 255 caracteres.")
        
        cache_collection = db.get_collection(collection_name)

        # Verificar se a coleÃ§Ã£o existe e estÃ¡ vazia
        if cache_collection.count_documents({}) == 0:
            print(f"âš  Criando a coleÃ§Ã£o `{collection_name}`")
        else:
            print(f"âš  ColeÃ§Ã£o `{collection_name}` encontrada!")


        # Testar a conexÃ£o
        client.server_info()  # Isso forÃ§a uma conexÃ£o para validar a URI
        print("âœ… Conectado ao MongoDB Atlas")

    except Exception as e:
        print(f"âš  Erro ao conectar ao MongoDB: {e}")
        cache_collection = None
else:
    print("âš  MongoDB nÃ£o configurado. Cache serÃ¡ ignorado.")

# Garantir fechamento da conexÃ£o ao encerrar o script
def close_mongo_connection():
    if client:
        client.close()
        print("ðŸ”Œ ConexÃ£o com MongoDB fechada.")
atexit.register(close_mongo_connection)

def calculate_hash(file_path):
    # Verifica se o caminho Ã© um arquivo regular e nÃ£o um diretÃ³rio
    if not os.path.isfile(file_path):
        print(f"âš  Ignorando diretÃ³rio: {file_path}")
        return None  # Retorna None ou outro valor adequado para indicar que o hash nÃ£o foi calculado

    # Se for um arquivo, calcula o hash
    hasher = hashlib.sha256()
    try:
        with open(file_path, 'rb') as f:
            hasher.update(f.read())
        return hasher.hexdigest()
    except Exception as e:
        print(f"âŒ Erro ao calcular hash para o arquivo {file_path}: {e}")
        return None
    
# Definindo a funÃ§Ã£o para verificar a conexÃ£o
def check_conn():
    if cache_collection is None:
        print("âš  Aviso: `cache_collection` estÃ¡ None. O cache nÃ£o serÃ¡ salvo!")
        return
    # Testando a conexÃ£o com o MongoDB
    print("ðŸ”¬ Testando leitura do MongoDB...")
    try:
        cache_collection.count_documents({})
    except Exception as e:
        print(f"âŒ Erro ao ler MongoDB: {e}")
    
def get_cache():
    if cache_collection is None:
        print("âš  Aviso: `cache_collection` estÃ¡ None. O cache nÃ£o serÃ¡ salvo!")
        return {}
    
    # Carregar o cache como um dicionÃ¡rio, onde a chave Ã© o file_path e o valor Ã© o hash
    return {doc["file_path"]: doc["hash"] for doc in cache_collection.find({}, {"_id": 0, "file_path": 1, "hash": 1})}

def update_cache(file_path, file_hash):
    if cache_collection is not None:
        # relative_path = os.path.relpath(file_path, SCAN_DIR)
        print(f"ðŸ“ Atualizando cache no MongoDB: {file_path} -> {file_hash}")  # <--- DEBUG
        cache_collection.update_one(
            {"file_path": file_path}, 
            {"$set": {"hash": file_hash}}, 
            upsert=True
        )
    else:
        print("âš  Aviso: `cache_collection` estÃ¡ None. O cache nÃ£o serÃ¡ salvo!")

def run_command(command, cwd=None):
    try:
        result = subprocess.run(command, shell=False, check=True, capture_output=True, text=True, cwd=cwd)
        print(result.stdout)
    except subprocess.CalledProcessError as e:
        print(f"âš  Erro ao executar o comando {' '.join(command)}: {e.stderr}")

def install_dependencies():
    if Path(SCAN_DIR, "requirements.txt").exists():
        print("ðŸ“¦ Instalando dependÃªncias Python (pip)...")
        run_command(["pip", "install", "-r", "requirements.txt"], cwd=SCAN_DIR)
    elif Path(SCAN_DIR, "pyproject.toml").exists():
        print("ðŸ“¦ Instalando dependÃªncias Python (Poetry)...")
        run_command(["poetry", "install"], cwd=SCAN_DIR)
    elif Path(SCAN_DIR, "Pipfile").exists():
        print("ðŸ“¦ Instalando dependÃªncias Python (Pipenv)...")
        run_command(["pipenv", "install"], cwd=SCAN_DIR)
    else:
        print("âš  Nenhum arquivo de dependÃªncias encontrado para Python. Pulando instalaÃ§Ã£o.")
    
    if Path(SCAN_DIR, "package.json").exists():
        print("ðŸ“¦ Instalando dependÃªncias Node.js...")
        run_command(["npm", "install"], cwd=SCAN_DIR)
    
    if Path(SCAN_DIR, "composer.json").exists():
        print("ðŸ“¦ Instalando dependÃªncias PHP...")
        run_command(["composer", "install"], cwd=SCAN_DIR)

def run_sast_scan():
    if not Path(SCAN_DIR).exists():
        print(f"âŒ Erro: Nenhum diretÃ³rio montado em /app/{destination}")
        return
    
    install_dependencies()
    check_conn()
    cache = get_cache()

    for file_path in Path(SCAN_DIR).rglob("*.py"):
        if any(ignored in file_path.parts for ignored in IGNORED_DIRS):
            continue
        file_hash = calculate_hash(file_path)
        cache = get_cache()
        if cache.get(str(file_path)) != file_hash:
            print(f"ðŸ” Escaneando {file_path} com bandit...")
            run_command(["bandit", "-r", str(file_path)])
            update_cache(str(file_path), file_hash)
        else:
            print(f"âœ… Ignorando {file_path} (sem mudanÃ§as)")

    for file_path in Path(SCAN_DIR).rglob("*.php"):
        if any(ignored in file_path.parts for ignored in IGNORED_DIRS):
            continue
        file_hash = calculate_hash(file_path)
        cache = get_cache()
        if cache.get(str(file_path)) != file_hash:
            print(f"ðŸ” Escaneando {file_path} com phpstan...")
            run_command(["phpstan", "analyse", str(file_path), "--level", "4"])
            update_cache(str(file_path), file_hash)
        else:
            print(f"âœ… Ignorando {file_path} (sem mudanÃ§as)")

    for file_path in Path(SCAN_DIR).rglob("*.js"):
        if any(ignored in file_path.parts for ignored in IGNORED_DIRS):
            continue
        file_hash = calculate_hash(file_path)
        cache = get_cache()
        if cache.get(str(file_path)) != file_hash:
            print(f"ðŸ” Escaneando {file_path} com njsscan...")
            run_command(['njsscan', str(file_path), '--json'])
            update_cache(str(file_path), file_hash)
        else:
            print(f"âœ… Ignorando {file_path} (sem mudanÃ§as)")

    run_command(["git", "config", "--global", "--add", "safe.directory", SCAN_DIR])

    # print("ðŸ” Rodando Semgrep...")
    # try:
    #     subprocess.run(["semgrep", "ci"], cwd=SCAN_DIR, check=True, capture_output=True, text=True)
    # except subprocess.CalledProcessError as e:
    #     print(f"âš  Erro ao executar Semgrep CI: {e.stderr}")

    print("âœ… AnÃ¡lise concluÃ­da!")

if __name__ == "__main__":
    run_sast_scan()
